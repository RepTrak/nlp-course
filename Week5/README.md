# Week 5
## Transformers

During this lesson we will cover the dominant approach these days in NLP - transformers. We will see how attention became not just improvement for RNN, but became a separate algorithm itself. Also we will talk about different variants of attention - and how their combination resulted in appearance of Transformers
### Link to seminar #5 in google colab:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RepTrak/nlp-course/blob/develop/Week5/seminar_5.ipynb)

### Link to homework #5 in google colab:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RepTrak/nlp-course/blob/develop/Week5/homework_5.ipynb)
